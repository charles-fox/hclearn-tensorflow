{
 "metadata": {
  "name": "",
  "signature": "sha256:8892fada6deb6c765a0c34d75c5d058483d5de21216d95133dd49be596401e06"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Raw code from functions in the hclearn folder, called by go.py, to ultimately generate the figures from Saul, Prescott & Fox 2011"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Import all the code dependencies\n",
      "\n",
      "# Moving code here so dependencies will be removed over time\n",
      "\n",
      "\n",
      "#import matplotlib\n",
      "#matplotlib.use('Agg')\n",
      "\"\"\" For iPython notebook inline plotting\"\"\"\n",
      "%matplotlib inline \n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "from hcq import *\n",
      "from gui import *\n",
      "from location import *\n",
      "from paths import *\n",
      "#from makeMaze import makeMaze\n",
      "\n",
      "#from os import sys\n",
      "import os\n",
      "import re\n",
      "import cv\n",
      "\n",
      "import learnWeights\n",
      "import sys\n",
      "\n",
      "#rootFolder = \"/Users/alansaul/Work/CompSci/SURE/hclearn_alan/\"\n",
      "rootFolder = \"/Users/mathew/work/hclearn/\"\n",
      "\n",
      "#This is the folder being used by makeSURFRepresentation to create the surf features for learnWeights\n",
      "prefixFolder = rootFolder + \"DCSCourtyard/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Check whether input arguments have been provided, if so check what they are. \n",
      "If not, set defaults for whether to use 'NewDG' in makeMaze.py, and the learning rate\n",
      "\"\"\"\n",
      "if len(sys.argv) == 3:\n",
      "    b_useNewDG = (sys.argv[1] == \"True\")\n",
      "    learningRate = float(sys.argv[2])\n",
      "else:\n",
      "    b_useNewDG = True\n",
      "    learningRate = 0.01\n",
      "    \n",
      "print(\"Sys:%d\" % len(sys.argv))\n",
      "print(\"DG:%s\" % b_useNewDG)\n",
      "print(\"LR:%f\" % learningRate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sys:7\n",
        "DG:True\n",
        "LR:0.010000\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Set parameters for constructing a maze environment and for training the model \"\"\"\n",
      "\n",
      "\"\"\" Ensures numbers aren't too long for printing \"\"\"\n",
      "np.set_printoptions(threshold=sys.maxint)         #=format short in matlab. \n",
      "\n",
      "\"\"\" Square maze with N places per arm, with (N,N) specifying the center \"\"\"\n",
      "N_mazeSize=3 \n",
      "T=3000   #trained on 30000   #better to have one long path than multi epochs on overfit little path\n",
      "b_learnWeights=True\n",
      "b_plot=True\n",
      "b_inference=True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Set up SURFExtractor object class. This is reasonably hefty but should make sense \"\"\"\n",
      "class SURFExtractor(object):\n",
      "    directions = ['N','E','S','W']\n",
      "#Stores the featuresDict, filesDict and featuresDescDict\n",
      "\n",
      "#Given a folder it will extract descriptors, merge them and generate the featureVectors for each image, and store them\n",
      "\n",
      "    #Requires the folder name\n",
      "    def __init__(self, folderName, maxFeaturesForMerging=10, maxFeaturesForMatching=20, mergeThreshold=0.15, matchThreshold=0.2):\n",
      "        self.folder = folderName\n",
      "        self.maxFeaturesForMerging = maxFeaturesForMerging\n",
      "        self.maxFeaturesForMatching = maxFeaturesForMatching\n",
      "        self.mergeThreshold = mergeThreshold\n",
      "        self.matchThreshold = matchThreshold\n",
      "\n",
      "    \"\"\"  Generate featureVectors \"\"\"\n",
      "    def generateFeatureRepresentations(self, byFolder=1):\n",
      "        if self.folder:\n",
      "            #First extract the files\n",
      "            if byFolder:\n",
      "                self.extractFilesByFolder(self.folder)\n",
      "            else:\n",
      "                self.extractFilesByPrefix(self.folder)\n",
      "\n",
      "            #Extract the descriptors of all top X features\n",
      "            self.extractDescriptors(self.files, self.maxFeaturesForMerging)\n",
      "\n",
      "            #print(\"Descriptors before merge:\\n%s\" % self.descriptors)\n",
      "            print(\"Merge threshold:\\n%s\" % self.mergeThreshold)\n",
      "            #Merge features so that we only have a small subset which are used to describe each image \n",
      "            #Unless otherwise stated this will use the FIRST image of each direction ONLY to train with\n",
      "            self.mergeFeatures()\n",
      "            #print(\"Merged features:\\n%s\" % self.mergedFeatures)\n",
      "\n",
      "            #Generate features for each image\n",
      "            #Get more features than we used for merging to be used for matching:\n",
      "            self.extractDescriptors(self.files, self.maxFeaturesForMatching)\n",
      "\n",
      "            self.generateFeatureVectors()\n",
      "        else:\n",
      "            raise NameError(\"Folder to select features from has not been provided\")\n",
      "    \n",
      "    \"\"\" Extract files by name prefix, store in dictionary \"\"\"\n",
      "    def extractFilesByPrefix(self, folder):\n",
      "        self.files = {}\n",
      "        #Key should be of form ((x,y),dir)\n",
      "        if os.path.exists(folder):\n",
      "            for file in os.listdir(folder):\n",
      "                parts = re.split(\"[-,\\.]\", file)\n",
      "                #Test that it is (NUM-NUM-DIRECTION-whatever)\n",
      "                if len(parts)>=2 and parts[0].isdigit() and parts[0].isdigit() and (parts[2][0].isalpha and len(parts[2]) == 1):\n",
      "                    if parts[2][0] in self.directions:\n",
      "                        key = ((int(parts[0]), int(parts[1])),parts[2])\n",
      "                        #If it doesnt already exist, make this key\n",
      "                        if key not in self.files.keys():\n",
      "                            self.files[key] = []\n",
      "                        fullFilePath = os.path.join(folder,file)\n",
      "                        #Add the new file onto the end of the keys list (since there can be multiple images for one direction)\n",
      "                        self.files[key].append(fullFilePath)\n",
      "                    else:\n",
      "                        raise NameError(\"Heading is: %s\\nit should be N S E or W\" % parts[2])\n",
      "                else:\n",
      "                    print folder\n",
      "                    print file\n",
      "                    #raise NameError(\"File: %s\\ndoes not fit naming convention INT-INT-HEADING\" % file)\n",
      "        else:\n",
      "            raise NameError(\"Folder does not exists\")\n",
      "    \n",
      "    \"\"\" Extract maxFeaturesPerImage best descriptors per image and store in dictionary \"\"\"\n",
      "    def extractDescriptors(self, files, maxNumOfDescriptors):\n",
      "        self.descriptors = {}\n",
      "        for (loc, dir) in files.keys():\n",
      "            #print(\"\\n%d, %s key\" % (loc,dir))\n",
      "            self.descriptors[(loc,dir)] = []\n",
      "            for image in files[(loc,dir)]:\n",
      "                cvIm = cv.LoadImageM(image, cv.CV_LOAD_IMAGE_GRAYSCALE)\n",
      "                imFeatures = extractSURFFeatures(cvIm,0,maxNumOfDescriptors)\n",
      "                self.descriptors[(loc,dir)].append(imFeatures)\n",
      "                \n",
      "    \"\"\" Use the descriptors recently extracted to merge them down into a subset describing lots of them \"\"\"\n",
      "    def mergeFeatures(self, random=0):\n",
      "        #Make a subset of all the descriptors\n",
      "        if random:\n",
      "            #TODO: Add random selection of descriptors rather than just first images of each direction\n",
      "            #Randomly choose 'random' features from the dictionary\n",
      "            pass\n",
      "        else:\n",
      "            #Take the first picture from each loc, dir pair\n",
      "            imageDescs = self.getFirstDescs()\n",
      "\n",
      "        print(\"Before:\\n%d,%d\" % (imageDescs.shape))\n",
      "        #merge the features within range\n",
      "        self.mergedFeatures = mergeFeatures(imageDescs, self.mergeThreshold)\n",
      "        print(\"After:\\n%d,%d\" % (self.mergedFeatures.shape))\n",
      "        \n",
      "    \"\"\" Get the all of the descriptors for the first image \"\"\"\n",
      "    def getFirstDescs(self):\n",
      "        #Check that the dictionary isn't empty...\n",
      "        if self.descriptors:\n",
      "            #Do something more pythonic?\n",
      "            first = True\n",
      "            for key in self.descriptors.keys():\n",
      "                if len(self.descriptors[key]) > 0:\n",
      "                    #If the features already exists, append the new descriptors on, else initialise it \n",
      "                    if first:\n",
      "                        #Get the first images descriptors in this list of several images descriptors\n",
      "                        features = self.descriptors[key][0]\n",
      "                        first = False\n",
      "                    else:\n",
      "                        features = np.vstack((features, self.descriptors[key][0]))\n",
      "            return features\n",
      "        else:\n",
      "            raise NameError('Dictionary of descriptors is empty, there should be items in it in order to get the first ones!')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Generate a dictionary of SURF features \"\"\"\n",
      "def makeSURFRepresentation():\n",
      "    #Make all things SURFY (its dictionary) and give back to makeMaze\n",
      "    se = SURFExtractor(prefixFolder) \n",
      "\n",
      "    #se.folder = prefixFolder\n",
      "    #FIX: If two photos are exactly the same, this will fail as they will be merged!\n",
      "    se.mergeThreshold = 0.06 #0.05\n",
      "    se.matchThreshold = 0.2\n",
      "    se.generateFeatureRepresentations(0)\n",
      "    print(\"FEATUREDESCDICT: %s\" % se.featuresDescDict)\n",
      "    return se.featuresDescDict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Extract SURF features (between 10000 and 30000 are good values) \"\"\"\n",
      "def extractSURFFeatures(image,draw, N=7):\n",
      "    (keypoints, descriptors) = cv.ExtractSURF(image, None, cv.CreateMemStorage(), (0, 100, 3, 2) )\n",
      "\n",
      "    #Want to take the X best ones\n",
      "    sortedDescriptorListPairs = [descriptor for keypoint, descriptor in sorted(zip(keypoints, descriptors), key=(lambda (keypoint, descriptors): keypoint[4]), reverse = True) ]\n",
      "    #np.array(sortedDescriptorListPairs[0:N])\n",
      "    #print(\"Num of keypoints: %d  Num of descriptors: %d \" % (len(keypoints), len(descriptors)))\n",
      "    if draw:\n",
      "        for ((x, y), laplacian, size, dir, hessian) in keypoints:\n",
      "            #print \"x=%d y=%d laplacian=%d size=%d dir=%f hessian=%f\" % (x, y, laplacian, size, dir, hessian)\n",
      "            #For each feature draw a circle around it\n",
      "            #Careful! Drawing on the images changes the images!!!\n",
      "            cv.Circle(image, (int(x),int(y)), size, (255.0, 0.0, 0.0,  0.0), 2)\n",
      "    #return np.array(descriptors)\n",
      "    return np.array(sortedDescriptorListPairs[0:N])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" makeSURFRepresentation() call runs the whole show detailed above \"\"\"\n",
      "#[dictSenses, dictAvailableActions, dictNext] = makeMaze(N_mazeSize, b_useNewDG)     #make maze, including ideal percepts at each place\n",
      "surfDict=None\n",
      "if b_useNewDG:\n",
      "    print(\"Generating SURF representations...\")\n",
      "    surfDict = makeSURFRepresentation()\n",
      "\n",
      "\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Generating SURF representations...\n",
        "/Users/mathew/work/hclearn/DCSCourtyard/\n",
        ".DS_Store\n",
        "Merge threshold:\n",
        "0.06"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Before:\n",
        "280,64\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "global name 'mergeFeatures' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-13-e9563294673c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb_useNewDG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generating SURF representations...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msurfDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeSURFRepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-9-011a60a66ca8>\u001b[0m in \u001b[0;36mmakeSURFRepresentation\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmergeThreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.06\u001b[0m \u001b[0;31m#0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatchThreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerateFeatureRepresentations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FEATUREDESCDICT: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturesDescDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturesDescDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-12-3864cc7a5ceb>\u001b[0m in \u001b[0;36mgenerateFeatureRepresentations\u001b[0;34m(self, byFolder)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#Merge features so that we only have a small subset which are used to describe each image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m#Unless otherwise stated this will use the FIRST image of each direction ONLY to train with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmergeFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;31m#print(\"Merged features:\\n%s\" % self.mergedFeatures)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-12-3864cc7a5ceb>\u001b[0m in \u001b[0;36mmergeFeatures\u001b[0;34m(self, random)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Before:\\n%d,%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimageDescs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m#merge the features within range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmergedFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmergeFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageDescs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmergeThreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After:\\n%d,%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmergedFeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: global name 'mergeFeatures' is not defined"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"SURFDICTKEYS:%s\" % surfDict.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}